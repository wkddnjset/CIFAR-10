{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifier for CIFAT-10\n",
    "\n",
    "#### Load_Dataset : Constomize CIFAR-10 Image Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import Load_Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load Dataset from Load_Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = Load_Dataset.load_data()\n",
    "data_reshape = Load_Dataset.reshape_data(data_set)\n",
    "\n",
    "train_X = data_reshape['images_train']\n",
    "train_Y = data_reshape['labels_train']\n",
    "test_X = data_reshape['images_test']\n",
    "test_Y = data_reshape['labels_test']\n",
    "classes = data_set['classes']\n",
    "\n",
    "train_X[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32, name='X')\n",
    "Y = tf.placeholder(shape=[None], dtype=tf.uint8, name='Y')\n",
    "W = tf.Variable(tf.zeros([3072, 10]), name='W')\n",
    "B = tf.Variable(tf.zeros([10]), name='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, name):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal(shape=weight_shape, mean=0.0, stddev=0.02, name='layer_W'))\n",
    "        L = tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME', name='conv')\n",
    "        relu = tf.nn.relu(L, name='relu')\n",
    "        output = tf.nn.max_pool(L, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pooling')\n",
    "        return W, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connect(input, weight_shape, bias_shape, name):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.get_variable('lay_W', shape=weight_shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        B = tf.Variable(tf.zeros(bias_shape), name='ful_B')\n",
    "        H = tf.matmul(input, W, name='ful_H') + B\n",
    "        softmax = tf.nn.softmax(H, name='softmaxw')\n",
    "        return H, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Layer 1 => 0-W, 1-B, 2-W, 3-output\n",
    "layer_1 = layer(X, [2, 2, 3, 32], 'first')[1]\n",
    "\n",
    "layer_2 = layer(layer_1, [2, 2, 32, 64], 'second')[1]\n",
    "\n",
    "# reshape Last output to vector\n",
    "vec_layer = tf.reshape(layer_2, [-1, 8*8*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fully connect => 0-output, 1-sofrmax\n",
    "ful_output, softmax = fully_connect(vec_layer, [8*8*64, 10], [10], 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## one_hot label\n",
    "Y_one = tf.one_hot(Y, 10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## minimize\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y_one, logits=ful_output, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "Accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(softmax, 1), tf.argmax(Y_one, 1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "loss ==>  20.1502830982\n",
      "epoch : 1\n",
      "loss ==>  16.7771908045\n",
      "epoch : 2\n",
      "loss ==>  15.3729429245\n",
      "epoch : 3\n",
      "loss ==>  14.2782267332\n",
      "epoch : 4\n",
      "loss ==>  13.3750494719\n",
      "epoch : 5\n",
      "loss ==>  12.6900279522\n",
      "epoch : 6\n",
      "loss ==>  12.1930938959\n",
      "epoch : 7\n",
      "loss ==>  11.791190505\n",
      "epoch : 8\n",
      "loss ==>  11.4442846775\n",
      "epoch : 9\n",
      "loss ==>  11.1600424051\n",
      "epoch : 10\n",
      "loss ==>  10.9255077839\n",
      "epoch : 11\n",
      "loss ==>  10.5946134329\n",
      "epoch : 12\n",
      "loss ==>  10.3736513853\n",
      "epoch : 13\n",
      "loss ==>  10.1937305331\n",
      "epoch : 14\n",
      "loss ==>  10.0404818654\n",
      "epoch : 15\n",
      "loss ==>  9.85088115931\n",
      "epoch : 16\n",
      "loss ==>  9.61280101538\n",
      "epoch : 17\n",
      "loss ==>  9.41454613209\n",
      "epoch : 18\n",
      "loss ==>  9.27944689989\n",
      "epoch : 19\n",
      "loss ==>  9.13621819019\n",
      "epoch : 20\n",
      "loss ==>  9.0127120018\n",
      "epoch : 21\n",
      "loss ==>  8.9101575613\n",
      "epoch : 22\n",
      "loss ==>  8.80753898621\n",
      "epoch : 23\n",
      "loss ==>  8.6791677475\n",
      "epoch : 24\n",
      "loss ==>  8.5543435216\n",
      "epoch : 25\n",
      "loss ==>  8.45723599195\n",
      "epoch : 26\n",
      "loss ==>  8.35358959436\n",
      "epoch : 27\n",
      "loss ==>  8.26973432302\n",
      "epoch : 28\n",
      "loss ==>  8.17704874277\n",
      "epoch : 29\n",
      "loss ==>  8.10058200359\n",
      "epoch : 30\n",
      "loss ==>  8.0214202404\n",
      "epoch : 31\n",
      "loss ==>  7.97673153877\n",
      "epoch : 32\n",
      "loss ==>  7.98356837034\n",
      "epoch : 33\n",
      "loss ==>  8.18144500256\n",
      "epoch : 34\n",
      "loss ==>  8.03084391356\n",
      "epoch : 35\n",
      "loss ==>  7.95500016212\n",
      "epoch : 36\n",
      "loss ==>  7.80196893215\n",
      "epoch : 37\n",
      "loss ==>  7.74053281546\n",
      "epoch : 38\n",
      "loss ==>  7.68770760298\n",
      "epoch : 39\n",
      "loss ==>  7.55435007811\n",
      "epoch : 40\n",
      "loss ==>  7.43453079462\n",
      "epoch : 41\n",
      "loss ==>  7.34285205603\n",
      "epoch : 42\n",
      "loss ==>  7.25888478756\n",
      "epoch : 43\n",
      "loss ==>  7.19923394918\n",
      "epoch : 44\n",
      "loss ==>  7.14395272732\n",
      "epoch : 45\n",
      "loss ==>  7.09364175797\n",
      "epoch : 46\n",
      "loss ==>  7.04595732689\n",
      "epoch : 47\n",
      "loss ==>  6.99831002951\n",
      "epoch : 48\n",
      "loss ==>  6.95518195629\n",
      "epoch : 49\n",
      "loss ==>  6.91715162992\n",
      "Accuracy :  0.6645\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    epoch = 50\n",
    "    batch_size = 5000\n",
    "    batch_count = 50000 // batch_size\n",
    "    for i in range(epoch):\n",
    "        print(\"epoch :\", i)\n",
    "        loss_total=0\n",
    "        for i in range(batch_count):\n",
    "            batch_index = i*batch_size\n",
    "            img = train_X[batch_index:batch_index+batch_size]\n",
    "            label = train_Y[batch_index:batch_index+batch_size]\n",
    "            _,loss_val = sess.run([train_op, loss],feed_dict={X:img, Y:label})\n",
    "            loss_total += loss_val\n",
    "        print(\"loss ==> \", loss_total)\n",
    "\n",
    "    test_img = test_X[:]\n",
    "    test_label = test_Y[:]\n",
    "    acc, pre = sess.run([Accuracy, Y_one], feed_dict={X:test_img, Y:test_label})\n",
    "    print(\"Accuracy : \", acc) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (32, 32, 3) for Tensor 'X:0', which has shape '(?, 32, 32, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-ca3d6681b30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------%s------\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1101\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (32, 32, 3) for Tensor 'X:0', which has shape '(?, 32, 32, 3)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        num = np.random.uniform(0, 10000, 10).astype(int)\n",
    "        test_img = test_X[num[i]]\n",
    "        test_label = test_Y[num[i]]\n",
    "        acc, pre = sess.run([Accuracy, Y_one], feed_dict={X:test_img, Y:test_label})\n",
    "        print(Image.fromarray(test_img))\n",
    "        print(\"------%s------\" % classes[np.argmax(pre)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIFElEQVR4nD1W2Y5kRxGNLe9Sdaur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\nwPrkSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FEFBC2C20F0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = np.random.uniform(0, 10000, 1).astype(int)\n",
    "test_img = test_X[num[0]]\n",
    "# Image.fromarray(test_img)\n",
    "Image.fromarray(train_X[10000].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
