{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifier for CIFAT-10\n",
    "\n",
    "#### Load_Dataset : Constomize CIFAR-10 Image Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import Load_Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load Dataset from Load_Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = Load_Dataset.load_data()\n",
    "data_reshape = Load_Dataset.reshape_data(data_set)\n",
    "\n",
    "train_X = data_reshape['images_train']\n",
    "train_Y = data_reshape['labels_train']\n",
    "test_X = data_reshape['images_test']\n",
    "test_Y = data_reshape['labels_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32, name='X')\n",
    "Y = tf.placeholder(shape=[None], dtype=tf.uint8, name='Y')\n",
    "W = tf.Variable(tf.zeros([3072, 10]), name='W')\n",
    "B = tf.Variable(tf.zeros([10]), name='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(input, weight_shape, name):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal(shape=weight_shape, mean=0.0, stddev=0.02, name='layer_W'))\n",
    "        L = tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME', name='conv')\n",
    "        relu = tf.nn.relu(L, name='relu')\n",
    "        output = tf.nn.max_pool(L, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pooling')\n",
    "        return W, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connect(input, weight_shape, bias_shape, name):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.get_variable('ful_W', shape=weight_shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "        B = tf.Variable(tf.zeros(bias_shape), name='ful_B')\n",
    "        H = tf.matmul(input, W, name='ful_H') + B\n",
    "        softmax = tf.nn.softmax(H, name='softmaxw')\n",
    "        return H, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer 1 => 0-W, 1-B, 2-W, 3-output\n",
    "layer_1 = layer(X, [2, 2, 3, 32], 'first')[1]\n",
    "\n",
    "layer_2 = layer(layer_1, [2, 2, 32, 64], 'second')[1]\n",
    "\n",
    "# reshape Last output to vector\n",
    "vec_layer = tf.reshape(layer_2, [-1, 8*8*64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ful1_3/add:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"ful1_3/softmaxw:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## fully connect => 0-output, 1-sofrmax\n",
    "ful_output, softmax = fully_connect(vec_layer, [8*8*64, 10], [10], 'ful1')\n",
    "print(ful_output)\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## one_hot label\n",
    "Y_one = tf.one_hot(Y, 10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## minimize\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y_one, logits=ful_output, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "Accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(softmax, 1), tf.argmax(Y_one, 1)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "loss ==>  137.075204372\n",
      "epoch : 1\n",
      "loss ==>  24.0965044498\n",
      "epoch : 2\n",
      "loss ==>  16.718909502\n",
      "epoch : 3\n",
      "loss ==>  12.5249843597\n",
      "epoch : 4\n",
      "loss ==>  11.0780494213\n",
      "epoch : 5\n",
      "loss ==>  9.90970230103\n",
      "epoch : 6\n",
      "loss ==>  9.47206318378\n",
      "epoch : 7\n",
      "loss ==>  9.17908418179\n",
      "epoch : 8\n",
      "loss ==>  8.93826425076\n",
      "epoch : 9\n",
      "loss ==>  8.76218008995\n",
      "epoch : 10\n",
      "loss ==>  8.63074219227\n",
      "epoch : 11\n",
      "loss ==>  8.48962903023\n",
      "epoch : 12\n",
      "loss ==>  8.37132656574\n",
      "epoch : 13\n",
      "loss ==>  8.2615377903\n",
      "epoch : 14\n",
      "loss ==>  8.16776096821\n",
      "epoch : 15\n",
      "loss ==>  8.07616198063\n",
      "epoch : 16\n",
      "loss ==>  7.98842215538\n",
      "epoch : 17\n",
      "loss ==>  7.90094685555\n",
      "epoch : 18\n",
      "loss ==>  7.81561112404\n",
      "epoch : 19\n",
      "loss ==>  7.73667562008\n",
      "epoch : 20\n",
      "loss ==>  7.66360008717\n",
      "epoch : 21\n",
      "loss ==>  7.59478294849\n",
      "epoch : 22\n",
      "loss ==>  7.52839446068\n",
      "epoch : 23\n",
      "loss ==>  7.45912826061\n",
      "epoch : 24\n",
      "loss ==>  7.39351928234\n",
      "epoch : 25\n",
      "loss ==>  7.32578790188\n",
      "epoch : 26\n",
      "loss ==>  7.2594666481\n",
      "epoch : 27\n",
      "loss ==>  7.19594204426\n",
      "epoch : 28\n",
      "loss ==>  7.12517130375\n",
      "epoch : 29\n",
      "loss ==>  7.05462658405\n",
      "epoch : 30\n",
      "loss ==>  6.98865282536\n",
      "epoch : 31\n",
      "loss ==>  6.92049598694\n",
      "epoch : 32\n",
      "loss ==>  6.91217327118\n",
      "epoch : 33\n",
      "loss ==>  6.91155135632\n",
      "epoch : 34\n",
      "loss ==>  6.89319574833\n",
      "epoch : 35\n",
      "loss ==>  6.81980717182\n",
      "epoch : 36\n",
      "loss ==>  6.88979494572\n",
      "epoch : 37\n",
      "loss ==>  6.79538416862\n",
      "epoch : 38\n",
      "loss ==>  6.66194820404\n",
      "epoch : 39\n",
      "loss ==>  6.48167490959\n",
      "epoch : 40\n",
      "loss ==>  6.37351107597\n",
      "epoch : 41\n",
      "loss ==>  6.2726637125\n",
      "epoch : 42\n",
      "loss ==>  6.21160161495\n",
      "epoch : 43\n",
      "loss ==>  6.15019893646\n",
      "epoch : 44\n",
      "loss ==>  6.12070906162\n",
      "epoch : 45\n",
      "loss ==>  6.10705721378\n",
      "epoch : 46\n",
      "loss ==>  6.14935791492\n",
      "epoch : 47\n",
      "loss ==>  6.22204864025\n",
      "epoch : 48\n",
      "loss ==>  6.04508018494\n",
      "epoch : 49\n",
      "loss ==>  6.00497734547\n",
      "epoch : 50\n",
      "loss ==>  6.18875789642\n",
      "epoch : 51\n",
      "loss ==>  6.0384773016\n",
      "epoch : 52\n",
      "loss ==>  5.81274092197\n",
      "epoch : 53\n",
      "loss ==>  5.61329519749\n",
      "epoch : 54\n",
      "loss ==>  5.47076964378\n",
      "epoch : 55\n",
      "loss ==>  5.44559597969\n",
      "epoch : 56\n",
      "loss ==>  5.36806547642\n",
      "epoch : 57\n",
      "loss ==>  5.71066772938\n",
      "epoch : 58\n",
      "loss ==>  5.47750639915\n",
      "epoch : 59\n",
      "loss ==>  5.48317563534\n",
      "epoch : 60\n",
      "loss ==>  5.83683025837\n",
      "epoch : 61\n",
      "loss ==>  5.61651146412\n",
      "epoch : 62\n",
      "loss ==>  5.35890722275\n",
      "epoch : 63\n",
      "loss ==>  5.06933712959\n",
      "epoch : 64\n",
      "loss ==>  4.89702665806\n",
      "epoch : 65\n",
      "loss ==>  4.81351846457\n",
      "epoch : 66\n",
      "loss ==>  4.90121608973\n",
      "epoch : 67\n",
      "loss ==>  4.9116242528\n",
      "epoch : 68\n",
      "loss ==>  4.98624843359\n",
      "epoch : 69\n",
      "loss ==>  4.86239427328\n",
      "epoch : 70\n",
      "loss ==>  4.77258950472\n",
      "epoch : 71\n",
      "loss ==>  4.89431852102\n",
      "epoch : 72\n",
      "loss ==>  4.78036755323\n",
      "epoch : 73\n",
      "loss ==>  4.5265378952\n",
      "epoch : 74\n",
      "loss ==>  4.29898315668\n",
      "epoch : 75\n",
      "loss ==>  4.15486997366\n",
      "epoch : 76\n",
      "loss ==>  4.23631942272\n",
      "epoch : 77\n",
      "loss ==>  4.15507394075\n",
      "epoch : 78\n",
      "loss ==>  4.16118836403\n",
      "epoch : 79\n",
      "loss ==>  4.6902371645\n",
      "epoch : 80\n",
      "loss ==>  4.71585005522\n",
      "epoch : 81\n",
      "loss ==>  4.54867660999\n",
      "epoch : 82\n",
      "loss ==>  4.04708725214\n",
      "epoch : 83\n",
      "loss ==>  3.88315099478\n",
      "epoch : 84\n",
      "loss ==>  3.77562844753\n",
      "epoch : 85\n",
      "loss ==>  3.77618998289\n",
      "epoch : 86\n",
      "loss ==>  3.69022828341\n",
      "epoch : 87\n",
      "loss ==>  3.64072608948\n",
      "epoch : 88\n",
      "loss ==>  3.45744514465\n",
      "epoch : 89\n",
      "loss ==>  3.62630110979\n",
      "epoch : 90\n",
      "loss ==>  3.56367653608\n",
      "epoch : 91\n",
      "loss ==>  3.52686756849\n",
      "epoch : 92\n",
      "loss ==>  4.31265324354\n",
      "epoch : 93\n",
      "loss ==>  5.23929822445\n",
      "epoch : 94\n",
      "loss ==>  4.93720412254\n",
      "epoch : 95\n",
      "loss ==>  4.23468589783\n",
      "epoch : 96\n",
      "loss ==>  3.76381075382\n",
      "epoch : 97\n",
      "loss ==>  3.46206480265\n",
      "epoch : 98\n",
      "loss ==>  3.14239060879\n",
      "epoch : 99\n",
      "loss ==>  3.03100764751\n",
      "Accuracy :  [0.50579989]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    epoch = 100\n",
    "    batch_size = 10000\n",
    "    batch_count = 50000 // batch_size\n",
    "    for i in range(epoch):\n",
    "        print(\"epoch :\", i)\n",
    "        loss_total=0\n",
    "        for i in range(batch_count):\n",
    "            batch_index = i*batch_size\n",
    "            img = np.reshape(train_X[batch_index:batch_index+batch_size], [-1,3072])\n",
    "            label = train_Y[batch_index:batch_index+batch_size]\n",
    "            _,loss_val = sess.run([train_op, loss],feed_dict={X:img, Y:label})\n",
    "            loss_total += loss_val\n",
    "        print(\"loss ==> \", loss_total)\n",
    "\n",
    "    test_img = np.reshape(test_X[:], [-1, 3072])\n",
    "    test_label = test_Y[:]\n",
    "    acc = sess.run([Accuracy], feed_dict={X:test_img, Y:test_label})\n",
    "    print(\"Accuracy : \", acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
